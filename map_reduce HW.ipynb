{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab21230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m411.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /Users/sahasrakamatam/opt/anaconda3/lib/python3.9/site-packages (from PyPDF2) (4.3.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e49ccd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 to 3107 saved in file1.txt.\n"
     ]
    }
   ],
   "source": [
    "#extracting pages 3097 to 3107 and saving to FILE1.txt\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "harrypotter_pdf='hp_book.pdf'  \n",
    "\n",
    "start_page=3097\n",
    "end_page=3107\n",
    "\n",
    "with open(harrypotter_pdf, 'rb') as pdf_file:\n",
    "    read=PyPDF2.PdfReader(pdf_file)\n",
    "    write=PyPDF2.PdfWriter()\n",
    "\n",
    "    for i in range(start_page - 1, end_page):  \n",
    "        page=read.pages[i]\n",
    "        write.add_page(page)\n",
    "\n",
    "    with open('file1.txt', 'w', encoding='utf-8') as text_file:\n",
    "        for i in range(len(write.pages)):\n",
    "            page=write.pages[i]\n",
    "            page_text=page.extract_text()\n",
    "            text_file.write(page_text)\n",
    "\n",
    "print(f\"{start_page} to {end_page} saved in file1.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e851267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 to 109 saved in file2.txt.\n"
     ]
    }
   ],
   "source": [
    "#extracting pages 99 to 109 and saving to FILE2.txt\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "harrypotter_pdf='hp_book.pdf'  \n",
    "\n",
    "start_page=99\n",
    "end_page=109\n",
    "\n",
    "with open(harrypotter_pdf, 'rb') as pdf_file:\n",
    "    read=PyPDF2.PdfReader(pdf_file)\n",
    "    write=PyPDF2.PdfWriter()\n",
    "\n",
    "    for i in range(start_page - 1, end_page):  \n",
    "        page=read.pages[i]\n",
    "        write.add_page(page)\n",
    "\n",
    "    with open('file2.txt', 'w', encoding='utf-8') as text_file:\n",
    "        for i in range(len(write.pages)):\n",
    "            page=write.pages[i]\n",
    "            page_text=page.extract_text()\n",
    "            text_file.write(page_text)\n",
    "\n",
    "print(f\"{start_page} to {end_page} saved in file2.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a23e09a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "had: 29\n",
      "happened: 4\n",
      "every: 7\n",
      "time: 4\n",
      "he: 42\n",
      "tried: 2\n",
      "sitting: 1\n",
      "down: 2\n",
      "in: 22\n",
      "the: 104\n",
      "living: 2\n",
      "room: 2\n",
      "and: 45\n",
      "watching: 2\n",
      "television: 1\n",
      "with: 8\n",
      "his: 36\n",
      "aunt: 15\n",
      "uncle: 20\n",
      "almost: 2\n",
      "as: 16\n",
      "though: 4\n",
      "this: 8\n",
      "thought: 2\n",
      "fluttered: 1\n",
      "through: 4\n",
      "open: 4\n",
      "window: 8\n",
      "vernon: 5\n",
      "dursley: 1\n",
      "harry: 41\n",
      "s: 23\n",
      "suddenly: 1\n",
      "spoke: 1\n",
      "glad: 1\n",
      "to: 36\n",
      "see: 3\n",
      "boy: 6\n",
      "stopped: 1\n",
      "trying: 2\n",
      "butt: 1\n",
      "where: 1\n",
      "is: 2\n",
      "anyway: 2\n",
      "i: 9\n",
      "don: 5\n",
      "t: 12\n",
      "know: 10\n",
      "said: 18\n",
      "petunia: 12\n",
      "unconcernedly: 1\n",
      "not: 9\n",
      "house: 2\n",
      "v: 12\n",
      "ernon: 12\n",
      "grunted: 1\n",
      "news: 14\n",
      "scathingly: 1\n",
      "d: 2\n",
      "like: 4\n",
      "what: 11\n",
      "really: 4\n",
      "up: 8\n",
      "if: 9\n",
      "a: 44\n",
      "normal: 1\n",
      "cares: 1\n",
      "on: 13\n",
      "dudley: 3\n",
      "hasn: 1\n",
      "got: 2\n",
      "clue: 2\n",
      "going: 1\n",
      "doubt: 1\n",
      "knows: 1\n",
      "who: 5\n",
      "prime: 1\n",
      "minister: 1\n",
      "it: 16\n",
      "there: 5\n",
      "be: 5\n",
      "anything: 2\n",
      "about: 6\n",
      "lot: 3\n",
      "our: 5\n",
      "shh: 1\n",
      "oh: 1\n",
      "yes: 3\n",
      "sorry: 1\n",
      "dear: 1\n",
      "p: 7\n",
      "g: 7\n",
      "e: 9\n",
      "3: 1\n",
      "potter: 7\n",
      "order: 7\n",
      "of: 35\n",
      "phoenix: 7\n",
      "j: 7\n",
      "k: 7\n",
      "rowling: 7\n",
      "www: 11\n",
      "ztcprep: 11\n",
      "com: 11\n",
      "dursleys: 6\n",
      "fell: 2\n",
      "silent: 1\n",
      "listened: 1\n",
      "jingle: 1\n",
      "fruit: 1\n",
      "n: 1\n",
      "bran: 1\n",
      "breakfast: 1\n",
      "cereal: 1\n",
      "while: 1\n",
      "watched: 1\n",
      "mrs: 3\n",
      "figg: 2\n",
      "batty: 1\n",
      "cat: 2\n",
      "loving: 1\n",
      "old: 1\n",
      "lady: 1\n",
      "from: 12\n",
      "nearby: 2\n",
      "wisteria: 1\n",
      "w: 1\n",
      "alk: 1\n",
      "amble: 1\n",
      "slowly: 1\n",
      "past: 1\n",
      "she: 6\n",
      "was: 19\n",
      "frowning: 1\n",
      "muttering: 1\n",
      "herself: 1\n",
      "very: 4\n",
      "pleased: 1\n",
      "that: 19\n",
      "concealed: 1\n",
      "behind: 2\n",
      "bush: 2\n",
      "recently: 1\n",
      "taken: 1\n",
      "asking: 1\n",
      "him: 12\n",
      "around: 5\n",
      "for: 10\n",
      "tea: 4\n",
      "whenever: 1\n",
      "met: 1\n",
      "street: 5\n",
      "rounded: 1\n",
      "corner: 1\n",
      "vanished: 2\n",
      "view: 1\n",
      "before: 3\n",
      "voice: 5\n",
      "floated: 1\n",
      "out: 8\n",
      "again: 6\n",
      "dudders: 1\n",
      "at: 15\n",
      "polkisses: 1\n",
      "fondly: 1\n",
      "so: 6\n",
      "many: 1\n",
      "little: 3\n",
      "friends: 1\n",
      "popular: 1\n",
      "repressed: 1\n",
      "snort: 1\n",
      "dif: 2\n",
      "ficulty: 1\n",
      "were: 6\n",
      "astonishingly: 1\n",
      "stupid: 2\n",
      "their: 4\n",
      "son: 1\n",
      "they: 7\n",
      "swallowed: 1\n",
      "all: 7\n",
      "dim: 1\n",
      "witted: 1\n",
      "lies: 1\n",
      "having: 1\n",
      "ferent: 1\n",
      "member: 1\n",
      "gang: 2\n",
      "night: 2\n",
      "summer: 3\n",
      "holidays: 2\n",
      "knew: 2\n",
      "perfectly: 2\n",
      "well: 4\n",
      "been: 8\n",
      "anywhere: 1\n",
      "spent: 2\n",
      "evening: 4\n",
      "vandalizing: 1\n",
      "play: 1\n",
      "park: 1\n",
      "smoking: 1\n",
      "corners: 1\n",
      "throwing: 1\n",
      "stones: 1\n",
      "passing: 1\n",
      "cars: 1\n",
      "children: 1\n",
      "seen: 1\n",
      "them: 1\n",
      "during: 1\n",
      "walks: 1\n",
      "whinging: 1\n",
      "most: 1\n",
      "wandering: 1\n",
      "streets: 2\n",
      "scavenging: 1\n",
      "newspapers: 1\n",
      "bins: 1\n",
      "along: 1\n",
      "way: 3\n",
      "opening: 1\n",
      "notes: 1\n",
      "music: 1\n",
      "heralded: 1\n",
      "seven: 2\n",
      "o: 1\n",
      "clock: 1\n",
      "reached: 3\n",
      "ears: 1\n",
      "stomach: 2\n",
      "turned: 1\n",
      "over: 5\n",
      "perhaps: 4\n",
      "tonight: 1\n",
      "after: 2\n",
      "month: 1\n",
      "waiting: 2\n",
      "would: 4\n",
      "record: 1\n",
      "numbers: 1\n",
      "stranded: 2\n",
      "holidaymakers: 2\n",
      "fill: 1\n",
      "airports: 1\n",
      "spanish: 1\n",
      "baggage: 2\n",
      "handlers: 2\n",
      "strike: 2\n",
      "reaches: 1\n",
      "its: 1\n",
      "second: 1\n",
      "week: 1\n",
      "4: 1\n",
      "give: 2\n",
      "em: 1\n",
      "lifelong: 1\n",
      "siesta: 1\n",
      "snarled: 2\n",
      "end: 1\n",
      "newsreader: 2\n",
      "sentence: 1\n",
      "but: 7\n",
      "no: 3\n",
      "matter: 1\n",
      "outside: 2\n",
      "flower: 1\n",
      "bed: 1\n",
      "seemed: 2\n",
      "unclench: 1\n",
      "surely: 1\n",
      "have: 3\n",
      "first: 1\n",
      "item: 1\n",
      "death: 1\n",
      "destruction: 1\n",
      "more: 6\n",
      "important: 1\n",
      "than: 1\n",
      "let: 1\n",
      "long: 1\n",
      "slow: 1\n",
      "breath: 1\n",
      "stared: 3\n",
      "brilliant: 1\n",
      "blue: 1\n",
      "sky: 2\n",
      "day: 2\n",
      "same: 2\n",
      "tension: 2\n",
      "expectation: 1\n",
      "temporary: 1\n",
      "relief: 1\n",
      "then: 7\n",
      "mounting: 1\n",
      "always: 1\n",
      "growing: 1\n",
      "insistent: 1\n",
      "question: 1\n",
      "why: 5\n",
      "nothing: 2\n",
      "yet: 1\n",
      "kept: 2\n",
      "listening: 5\n",
      "just: 4\n",
      "case: 2\n",
      "some: 3\n",
      "small: 1\n",
      "recognized: 1\n",
      "by: 5\n",
      "muggles: 1\n",
      "an: 2\n",
      "unexplained: 1\n",
      "disappearance: 1\n",
      "or: 2\n",
      "strange: 1\n",
      "accident: 1\n",
      "followed: 2\n",
      "drought: 1\n",
      "southeast: 1\n",
      "hope: 1\n",
      "next: 2\n",
      "door: 1\n",
      "bellowed: 2\n",
      "sprinklers: 1\n",
      "three: 1\n",
      "morning: 1\n",
      "helicopter: 1\n",
      "crashed: 1\n",
      "field: 1\n",
      "surrey: 1\n",
      "famous: 2\n",
      "actress: 1\n",
      "divorce: 1\n",
      "her: 4\n",
      "husband: 1\n",
      "we: 4\n",
      "re: 6\n",
      "interested: 1\n",
      "sordid: 1\n",
      "af: 1\n",
      "fairs: 1\n",
      "snif: 1\n",
      "fed: 2\n",
      "obsessively: 1\n",
      "magazine: 1\n",
      "could: 7\n",
      "lay: 2\n",
      "bony: 1\n",
      "hands: 3\n",
      "closed: 2\n",
      "eyes: 3\n",
      "against: 1\n",
      "now: 6\n",
      "blazing: 1\n",
      "finally: 1\n",
      "bungy: 2\n",
      "budgie: 1\n",
      "has: 2\n",
      "found: 1\n",
      "novel: 1\n",
      "keeping: 1\n",
      "cool: 1\n",
      "lives: 1\n",
      "five: 1\n",
      "feathers: 1\n",
      "barnsley: 1\n",
      "learned: 1\n",
      "water: 2\n",
      "ski: 1\n",
      "mary: 1\n",
      "dorkins: 1\n",
      "went: 1\n",
      "find: 1\n",
      "opened: 1\n",
      "skiing: 1\n",
      "budgerigars: 1\n",
      "else: 1\n",
      "worth: 1\n",
      "hearing: 1\n",
      "rolled: 1\n",
      "cautiously: 1\n",
      "onto: 2\n",
      "front: 2\n",
      "5: 1\n",
      "raised: 2\n",
      "himself: 2\n",
      "knees: 1\n",
      "elbows: 1\n",
      "preparing: 1\n",
      "crawl: 1\n",
      "under: 4\n",
      "moved: 2\n",
      "two: 3\n",
      "inches: 1\n",
      "when: 3\n",
      "several: 2\n",
      "things: 1\n",
      "quick: 1\n",
      "succession: 1\n",
      "loud: 2\n",
      "echoing: 1\n",
      "crack: 1\n",
      "broke: 1\n",
      "sleepy: 1\n",
      "silence: 1\n",
      "gunshot: 1\n",
      "streaked: 1\n",
      "parked: 1\n",
      "car: 2\n",
      "flew: 1\n",
      "sight: 1\n",
      "shriek: 1\n",
      "oath: 1\n",
      "sound: 3\n",
      "breaking: 1\n",
      "china: 1\n",
      "came: 1\n",
      "signal: 1\n",
      "jumped: 1\n",
      "feet: 2\n",
      "pulling: 2\n",
      "waistband: 1\n",
      "jeans: 2\n",
      "thin: 3\n",
      "wooden: 1\n",
      "wand: 3\n",
      "unsheathing: 1\n",
      "sword: 1\n",
      "draw: 1\n",
      "full: 1\n",
      "height: 1\n",
      "top: 2\n",
      "head: 3\n",
      "collided: 1\n",
      "resultant: 1\n",
      "crash: 1\n",
      "made: 5\n",
      "scream: 1\n",
      "even: 2\n",
      "louder: 1\n",
      "felt: 2\n",
      "split: 1\n",
      "streaming: 1\n",
      "swayed: 1\n",
      "focus: 1\n",
      "spot: 1\n",
      "source: 1\n",
      "noise: 5\n",
      "barely: 2\n",
      "staggered: 1\n",
      "upright: 1\n",
      "lar: 1\n",
      "ge: 1\n",
      "purple: 2\n",
      "tightly: 1\n",
      "throat: 1\n",
      "put: 1\n",
      "away: 2\n",
      "into: 3\n",
      "ear: 1\n",
      "befor: 1\n",
      "anyone: 1\n",
      "sees: 1\n",
      "get: 4\n",
      "f: 2\n",
      "me: 6\n",
      "gasped: 1\n",
      "few: 4\n",
      "seconds: 2\n",
      "struggled: 1\n",
      "sausage: 1\n",
      "fingers: 1\n",
      "left: 2\n",
      "hand: 1\n",
      "right: 4\n",
      "maintaining: 1\n",
      "firm: 1\n",
      "grip: 1\n",
      "pain: 1\n",
      "gave: 2\n",
      "particularly: 1\n",
      "nasty: 2\n",
      "throb: 1\n",
      "yelped: 1\n",
      "released: 1\n",
      "received: 1\n",
      "electric: 1\n",
      "shock: 1\n",
      "invisible: 2\n",
      "force: 1\n",
      "sur: 1\n",
      "ged: 1\n",
      "nephew: 1\n",
      "making: 2\n",
      "impossible: 1\n",
      "hold: 1\n",
      "6: 1\n",
      "panting: 1\n",
      "forward: 1\n",
      "hydrangea: 1\n",
      "straightened: 1\n",
      "sign: 2\n",
      "caused: 1\n",
      "cracking: 3\n",
      "faces: 1\n",
      "peering: 1\n",
      "various: 2\n",
      "windows: 2\n",
      "stuf: 1\n",
      "hastily: 1\n",
      "back: 5\n",
      "look: 1\n",
      "innocent: 1\n",
      "lovely: 1\n",
      "shouted: 1\n",
      "waving: 1\n",
      "number: 1\n",
      "glaring: 1\n",
      "net: 1\n",
      "curtains: 1\n",
      "did: 3\n",
      "you: 12\n",
      "hear: 2\n",
      "backfire: 1\n",
      "quite: 1\n",
      "turn: 1\n",
      "continued: 1\n",
      "grin: 2\n",
      "horrible: 1\n",
      "manic: 1\n",
      "until: 1\n",
      "curious: 1\n",
      "neighbors: 1\n",
      "disappeared: 1\n",
      "became: 1\n",
      "grimace: 1\n",
      "rage: 1\n",
      "beckoned: 1\n",
      "toward: 1\n",
      "steps: 2\n",
      "closer: 1\n",
      "taking: 2\n",
      "care: 2\n",
      "stop: 1\n",
      "short: 1\n",
      "point: 2\n",
      "which: 2\n",
      "outstretched: 1\n",
      "resume: 1\n",
      "strangling: 1\n",
      "devil: 1\n",
      "do: 3\n",
      "mean: 2\n",
      "asked: 1\n",
      "croaky: 1\n",
      "trembled: 1\n",
      "fury: 1\n",
      "coldly: 1\n",
      "looking: 1\n",
      "still: 1\n",
      "hoping: 1\n",
      "person: 1\n",
      "racket: 1\n",
      "starting: 1\n",
      "pistol: 1\n",
      "didn: 2\n",
      "make: 1\n",
      "firmly: 1\n",
      "horsey: 1\n",
      "face: 2\n",
      "appeared: 2\n",
      "beside: 1\n",
      "wide: 1\n",
      "one: 2\n",
      "looked: 1\n",
      "livid: 1\n",
      "lurking: 1\n",
      "7: 1\n",
      "good: 1\n",
      "wer: 1\n",
      "doing: 2\n",
      "resigned: 1\n",
      "exchanged: 1\n",
      "looks: 1\n",
      "outrage: 1\n",
      "changes: 1\n",
      "clever: 1\n",
      "want: 1\n",
      "any: 1\n",
      "tosh: 1\n",
      "y: 2\n",
      "ou: 2\n",
      "your: 3\n",
      "careful: 1\n",
      "breathed: 1\n",
      "lowered: 2\n",
      "goggled: 1\n",
      "liar: 1\n",
      "are: 1\n",
      "those: 2\n",
      "too: 1\n",
      "lip: 1\n",
      "read: 1\n",
      "word: 1\n",
      "owls: 2\n",
      "bringing: 2\n",
      "aha: 1\n",
      "triumphant: 1\n",
      "whisper: 1\n",
      "pestilential: 1\n",
      "birds: 1\n",
      "hesitated: 1\n",
      "moment: 3\n",
      "cost: 1\n",
      "something: 2\n",
      "tell: 1\n",
      "truth: 1\n",
      "possibly: 1\n",
      "how: 2\n",
      "bad: 1\n",
      "admitting: 1\n",
      "8: 1\n",
      "aren: 1\n",
      "tonelessly: 1\n",
      "believe: 1\n",
      "once: 1\n",
      "forcefully: 1\n",
      "funny: 1\n",
      "temper: 1\n",
      "rising: 1\n",
      "call: 1\n",
      "wheeled: 2\n",
      "crossed: 1\n",
      "lawn: 1\n",
      "stepped: 1\n",
      "low: 1\n",
      "garden: 1\n",
      "wall: 1\n",
      "striding: 1\n",
      "trouble: 1\n",
      "later: 1\n",
      "pay: 1\n",
      "price: 1\n",
      "rudeness: 1\n",
      "much: 2\n",
      "pressing: 1\n",
      "matters: 1\n",
      "mind: 1\n",
      "sure: 3\n",
      "someone: 2\n",
      "apparating: 1\n",
      "disapparating: 1\n",
      "exactly: 1\n",
      "dobby: 4\n",
      "elf: 1\n",
      "air: 1\n",
      "possible: 1\n",
      "here: 1\n",
      "privet: 2\n",
      "drive: 2\n",
      "following: 1\n",
      "occurred: 1\n",
      "completely: 1\n",
      "deserted: 1\n",
      "become: 1\n",
      "walked: 1\n",
      "hardly: 1\n",
      "aware: 1\n",
      "route: 1\n",
      "pounded: 1\n",
      "these: 1\n",
      "often: 1\n",
      "lately: 1\n",
      "carried: 1\n",
      "favorite: 1\n",
      "haunts: 1\n",
      "automatically: 1\n",
      "glanced: 1\n",
      "9: 1\n",
      "shoulder: 1\n",
      "magical: 2\n",
      "near: 1\n",
      "among: 1\n",
      "petunias: 1\n",
      "dying: 1\n",
      "begonias: 1\n",
      "hadn: 3\n",
      "spoken: 1\n",
      "contact: 2\n",
      "hiding: 1\n",
      "feeling: 1\n",
      "frustration: 1\n",
      "peaked: 1\n",
      "certainty: 1\n",
      "leaked: 1\n",
      "desperate: 1\n",
      "tiniest: 1\n",
      "world: 1\n",
      "belonged: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def clean_text(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return words\n",
    "\n",
    "def map_count(text):\n",
    "    words = clean_text(text)\n",
    "    for word in words:\n",
    "        yield (word, 1)\n",
    "\n",
    "def reduce_count(data):\n",
    "    word_counts = Counter()\n",
    "    for word, count in data:\n",
    "        word_counts[word] += count\n",
    "    return word_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open('file1.txt', 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    map_data = list(map_count(text))\n",
    "    word_count = reduce_count(mapped_data)\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        print(f'{word}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c17852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–: 9\n",
      "j.k: 9\n",
      "rowling: 9\n",
      "wouldn’: 2\n",
      "—: 29\n",
      "weirdos: 1\n",
      "world’: 1\n",
      "wizarding: 1\n",
      "they’d: 2\n",
      "—”: 6\n",
      "hagrid: 20\n",
      "ernon: 3\n",
      "“i’m: 3\n",
      "dursley: 1\n",
      "i’m: 1\n",
      "…”: 1\n",
      "ernon’: 1\n",
      "again;: 1\n",
      "“that’: 1\n",
      ",”: 3\n",
      "www.ztcprep.com: 11\n",
      "“but: 3\n",
      "ol-: 1\n",
      "ou-: 1\n",
      "know-who?”: 1\n",
      "“good: 1\n",
      "anished: 1\n",
      "ter: 18\n",
      "yeh: 7\n",
      "that’: 1\n",
      "myst’ry: 1\n",
      "…: 7\n",
      "gettin’: 2\n",
      "an’: 10\n",
      "why’d: 1\n",
      "go?: 1\n",
      "“some: 1\n",
      "dunno: 2\n",
      "he’s: 1\n",
      "bidin’: 1\n",
      "don’: 3\n",
      "|: 8\n",
      "63: 1\n",
      "’em: 1\n",
      "outta: 1\n",
      "kinda: 1\n",
      "could’ve: 1\n",
      "comin’: 1\n",
      "“most: 1\n",
      "he’: 3\n",
      "oo: 1\n",
      "’cause: 1\n",
      "somethin’: 3\n",
      "goin’: 2\n",
      "hadn’: 4\n",
      "right.”: 1\n",
      "wizard?: 1\n",
      "him?: 2\n",
      "be?: 1\n",
      "he’d: 3\n",
      "dudley: 6\n",
      "vernon;: 1\n",
      "cupboard?: 1\n",
      "football?: 1\n",
      "“hagrid,”: 1\n",
      "“i: 4\n",
      "wizard.”: 1\n",
      "“not: 1\n",
      "eh?: 1\n",
      "angry?”: 1\n",
      "dudley’: 1\n",
      "64: 1\n",
      "it?: 1\n",
      "“see?”: 1\n",
      "“harry: 1\n",
      "you’ll: 1\n",
      "hogwarts.”: 1\n",
      "wasn’: 2\n",
      "“haven’: 1\n",
      "going?”: 1\n",
      "“he’: 1\n",
      "he’ll: 3\n",
      "i’ve: 1\n",
      "“if: 1\n",
      "muggle: 1\n",
      "won’: 3\n",
      "him,”: 2\n",
      "“stop: 1\n",
      "’s: 1\n",
      "hogwarts!: 1\n",
      "name’: 1\n",
      "fer: 4\n",
      "hogwarts: 2\n",
      "albus: 2\n",
      "dumbled—”: 1\n",
      "aying: 1\n",
      "tricks!”: 1\n",
      "vernon: 2\n",
      "“never: 1\n",
      "“—: 1\n",
      "insul: 1\n",
      "dumbledore: 2\n",
      "me!”: 1\n",
      "swishing: 1\n",
      "65: 1\n",
      "pig’: 1\n",
      "“shouldn’: 1\n",
      "didn’: 6\n",
      "do.”: 1\n",
      "“be: 1\n",
      "hogwarts,”: 1\n",
      "speakin’: 1\n",
      "yer: 5\n",
      "stuf: 2\n",
      "o’: 4\n",
      "“why: 2\n",
      "aren’: 1\n",
      "magic?”: 1\n",
      "“oh: 1\n",
      "meself: 1\n",
      "dumbledore.”: 1\n",
      "expelled?”: 1\n",
      "“it’s: 1\n",
      "we’ve: 1\n",
      "“gotta: 1\n",
      "that.”: 2\n",
      "66: 1\n",
      "“you: 1\n",
      "kip: 1\n",
      "that,”: 2\n",
      "“don’: 3\n",
      "pockets.”: 2\n",
      "67: 1\n",
      "diagon: 1\n",
      "“it: 1\n",
      "dream,”: 1\n",
      "i’ll: 2\n",
      "cupboard.”: 1\n",
      "ther: 1\n",
      "e’: 1\n",
      "ap: 2\n",
      "“all: 1\n",
      "right,”: 1\n",
      "up.”: 1\n",
      "hagrid’: 3\n",
      "68: 1\n",
      "lar: 1\n",
      "ge: 1\n",
      "“hagrid!”: 1\n",
      "“there’: 1\n",
      "“pay: 1\n",
      "“what?”: 1\n",
      "“he: 1\n",
      "payin’: 1\n",
      "deliverin’: 1\n",
      "teabags: 1\n",
      "strange-looking: 1\n",
      "“give: 1\n",
      "knuts,”: 1\n",
      "“knuts?”: 1\n",
      "“the: 1\n",
      "ones.”: 1\n",
      "69: 1\n",
      "“best: 1\n",
      "gotta: 1\n",
      "school.”: 1\n",
      "“um: 1\n",
      "hagrid?”: 1\n",
      "“mm?”: 1\n",
      "haven’: 1\n",
      "magic.”: 1\n",
      "“d’yeh: 1\n",
      "anything?”: 1\n",
      "“they: 1\n",
      "boy!: 1\n",
      "nah: 1\n",
      "gringotts: 2\n",
      "izards’: 1\n",
      "they’re: 1\n",
      "teh: 1\n",
      ".”: 1\n",
      "“wizards: 1\n",
      "?”: 2\n",
      "“just: 1\n",
      "goblins.”: 1\n",
      "70: 1\n",
      "“goblins: 1\n",
      "“yeah: 1\n",
      "yeh’d: 1\n"
     ]
    }
   ],
   "source": [
    "#number of times non-english words are used\n",
    "\n",
    "def english_words(english_file):\n",
    "    english_words = set()\n",
    "    with open(english_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            word = line.strip().lower()\n",
    "            english_words.add(word)\n",
    "    return english_words\n",
    "\n",
    "def remove_cf(word):\n",
    "    word = word.lower()\n",
    "    word = word.rstrip('.,') \n",
    "    return word\n",
    "\n",
    "def map_function(file1, english_words):\n",
    "    word_counts = {}\n",
    "    with open(file1, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.strip().split()\n",
    "            for word in words:\n",
    "                word = remove_cf(word)\n",
    "                if word and word not in english_words:\n",
    "                    if word in word_counts:\n",
    "                        word_counts[word] += 1\n",
    "                    else:\n",
    "                        word_counts[word] = 1\n",
    "    return word_counts\n",
    "\n",
    "def reduce_function(word_counts):\n",
    "    combined_counts = {}\n",
    "    for word_count in word_counts:\n",
    "        for word, count in word_count.items():\n",
    "            if word in combined_counts:\n",
    "                combined_counts[word] += count\n",
    "            else:\n",
    "                combined_counts[word] = count\n",
    "    return combined_counts\n",
    "\n",
    "english_file = 'USA.txt'\n",
    "file1 = 'file2.txt'\n",
    "\n",
    "english_words = english_words(english_file)\n",
    "\n",
    "word_counts = map_function(file1, english_words)\n",
    "\n",
    "combined_counts = reduce_function([word_counts])\n",
    "\n",
    "for word, count in combined_counts.items():\n",
    "    print(f'{word}: {count}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
